{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "\n",
    "from MNISTDataset import MNISTDataset\n",
    "from sklearn import datasets\n",
    "\n",
    "torch.manual_seed(17)\n",
    "np.random.seed(17)\n",
    "\n",
    "N = 1600\n",
    "batch = 32\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "g_train = MNISTDataset(digits.data[:1600], digits.target[:1600], N)\n",
    "data_loader = DataLoader(g_train, batch_size =  32, shuffle=True)\n",
    "\n",
    "g_test = MNISTDataset(digits.data[1600:], digits.target[1600:], 1765-N)\n",
    "test_loader = DataLoader(g_test, batch_size =  32, shuffle=True)\n",
    "\n",
    "# simple NN:\n",
    "class NN(nn.Module):   \n",
    "    def __init__(self, n1, n2, n3):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(n1, n2)\n",
    "        self.act = nn.ReLU()        \n",
    "        self.lin3 = nn.Linear(n2, n3)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        out = self.lin1(x)\n",
    "        out = self.act(out)\n",
    "        out = self.lin3(out)\n",
    "\n",
    "        return out \n",
    "    \n",
    "inp = 8\n",
    "\n",
    "net = NN(inp*inp, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in net.named_parameters():\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0 Loss 3.926954507827759\n",
      "Epoch 1 Iteration 1 Loss 3.306882619857788\n",
      "Epoch 1 Iteration 2 Loss 3.52573823928833\n",
      "Epoch 1 Iteration 3 Loss 3.4346632957458496\n",
      "Epoch 1 Iteration 4 Loss 3.4031739234924316\n",
      "Epoch 1 Iteration 5 Loss 3.3136603832244873\n",
      "Epoch 1 Iteration 6 Loss 3.098027229309082\n",
      "Epoch 1 Iteration 7 Loss 3.343773603439331\n",
      "Epoch 1 Iteration 8 Loss 3.1698598861694336\n",
      "Epoch 1 Iteration 9 Loss 3.3562471866607666\n",
      "Epoch 1 Iteration 10 Loss 2.755659818649292\n",
      "Epoch 1 Iteration 11 Loss 2.8606362342834473\n",
      "Epoch 1 Iteration 12 Loss 2.7058730125427246\n",
      "Epoch 1 Iteration 13 Loss 2.437093496322632\n",
      "Epoch 1 Iteration 14 Loss 3.0814177989959717\n",
      "Epoch 1 Iteration 15 Loss 2.823507308959961\n",
      "Epoch 1 Iteration 16 Loss 2.674312114715576\n",
      "Epoch 1 Iteration 17 Loss 2.9254772663116455\n",
      "Epoch 1 Iteration 18 Loss 2.484011173248291\n",
      "Epoch 1 Iteration 19 Loss 2.579915761947632\n",
      "Epoch 1 Iteration 20 Loss 2.6552836894989014\n",
      "Epoch 1 Iteration 21 Loss 2.7920103073120117\n",
      "Epoch 1 Iteration 22 Loss 2.6165733337402344\n",
      "Epoch 1 Iteration 23 Loss 2.3537375926971436\n",
      "Epoch 1 Iteration 24 Loss 2.4397428035736084\n",
      "Epoch 1 Iteration 25 Loss 2.3981521129608154\n",
      "Epoch 1 Iteration 26 Loss 2.3379740715026855\n",
      "Epoch 1 Iteration 27 Loss 2.4191882610321045\n",
      "Epoch 1 Iteration 28 Loss 2.3133976459503174\n",
      "Epoch 1 Iteration 29 Loss 2.397507429122925\n",
      "Epoch 1 Iteration 30 Loss 2.396409749984741\n",
      "Epoch 1 Iteration 31 Loss 2.193253993988037\n",
      "Epoch 1 Iteration 32 Loss 2.4239983558654785\n",
      "Epoch 1 Iteration 33 Loss 2.108400821685791\n",
      "Epoch 1 Iteration 34 Loss 2.066643238067627\n",
      "Epoch 1 Iteration 35 Loss 2.124931812286377\n",
      "Epoch 1 Iteration 36 Loss 2.471980571746826\n",
      "Epoch 1 Iteration 37 Loss 2.108520269393921\n",
      "Epoch 1 Iteration 38 Loss 2.1658143997192383\n",
      "Epoch 1 Iteration 39 Loss 2.1815617084503174\n",
      "Epoch 1 Iteration 40 Loss 1.9832844734191895\n",
      "Epoch 1 Iteration 41 Loss 1.926396131515503\n",
      "Epoch 1 Iteration 42 Loss 2.044278621673584\n",
      "Epoch 1 Iteration 43 Loss 1.9087046384811401\n",
      "Epoch 1 Iteration 44 Loss 2.1868338584899902\n",
      "Epoch 1 Iteration 45 Loss 1.9826511144638062\n",
      "Epoch 1 Iteration 46 Loss 1.9562324285507202\n",
      "Epoch 1 Iteration 47 Loss 2.0165774822235107\n",
      "Epoch 1 Iteration 48 Loss 2.194437265396118\n",
      "Epoch 1 Iteration 49 Loss 2.0394821166992188\n",
      "Epoch 2 Iteration 0 Loss 1.7228114604949951\n",
      "Epoch 2 Iteration 1 Loss 1.938169240951538\n",
      "Epoch 2 Iteration 2 Loss 1.9165809154510498\n",
      "Epoch 2 Iteration 3 Loss 1.92527174949646\n",
      "Epoch 2 Iteration 4 Loss 2.1561827659606934\n",
      "Epoch 2 Iteration 5 Loss 1.9934403896331787\n",
      "Epoch 2 Iteration 6 Loss 2.200779914855957\n",
      "Epoch 2 Iteration 7 Loss 1.9962365627288818\n",
      "Epoch 2 Iteration 8 Loss 2.0050313472747803\n",
      "Epoch 2 Iteration 9 Loss 1.8386887311935425\n",
      "Epoch 2 Iteration 10 Loss 1.8934894800186157\n",
      "Epoch 2 Iteration 11 Loss 1.8387856483459473\n",
      "Epoch 2 Iteration 12 Loss 1.6412171125411987\n",
      "Epoch 2 Iteration 13 Loss 1.7157468795776367\n",
      "Epoch 2 Iteration 14 Loss 1.6811854839324951\n",
      "Epoch 2 Iteration 15 Loss 1.5983244180679321\n",
      "Epoch 2 Iteration 16 Loss 1.8152599334716797\n",
      "Epoch 2 Iteration 17 Loss 1.7767415046691895\n",
      "Epoch 2 Iteration 18 Loss 1.8959951400756836\n",
      "Epoch 2 Iteration 19 Loss 1.6289103031158447\n",
      "Epoch 2 Iteration 20 Loss 1.7395490407943726\n",
      "Epoch 2 Iteration 21 Loss 1.9236189126968384\n",
      "Epoch 2 Iteration 22 Loss 1.7765694856643677\n",
      "Epoch 2 Iteration 23 Loss 1.7628356218338013\n",
      "Epoch 2 Iteration 24 Loss 1.6548540592193604\n",
      "Epoch 2 Iteration 25 Loss 1.5636420249938965\n",
      "Epoch 2 Iteration 26 Loss 1.904271125793457\n",
      "Epoch 2 Iteration 27 Loss 1.5339199304580688\n",
      "Epoch 2 Iteration 28 Loss 1.7272602319717407\n",
      "Epoch 2 Iteration 29 Loss 1.709316372871399\n",
      "Epoch 2 Iteration 30 Loss 1.6428009271621704\n",
      "Epoch 2 Iteration 31 Loss 1.6975094079971313\n",
      "Epoch 2 Iteration 32 Loss 1.4747697114944458\n",
      "Epoch 2 Iteration 33 Loss 1.412925124168396\n",
      "Epoch 2 Iteration 34 Loss 1.5802136659622192\n",
      "Epoch 2 Iteration 35 Loss 1.5754059553146362\n",
      "Epoch 2 Iteration 36 Loss 1.4539000988006592\n",
      "Epoch 2 Iteration 37 Loss 1.5104104280471802\n",
      "Epoch 2 Iteration 38 Loss 1.7101410627365112\n",
      "Epoch 2 Iteration 39 Loss 1.6354398727416992\n",
      "Epoch 2 Iteration 40 Loss 1.5981483459472656\n",
      "Epoch 2 Iteration 41 Loss 1.4018090963363647\n",
      "Epoch 2 Iteration 42 Loss 1.54228937625885\n",
      "Epoch 2 Iteration 43 Loss 1.5937323570251465\n",
      "Epoch 2 Iteration 44 Loss 1.436498999595642\n",
      "Epoch 2 Iteration 45 Loss 1.3556748628616333\n",
      "Epoch 2 Iteration 46 Loss 1.5428104400634766\n",
      "Epoch 2 Iteration 47 Loss 1.4642620086669922\n",
      "Epoch 2 Iteration 48 Loss 1.4390895366668701\n",
      "Epoch 2 Iteration 49 Loss 1.5779966115951538\n",
      "Epoch 3 Iteration 0 Loss 1.451743483543396\n",
      "Epoch 3 Iteration 1 Loss 1.4514291286468506\n",
      "Epoch 3 Iteration 2 Loss 1.5640634298324585\n",
      "Epoch 3 Iteration 3 Loss 1.4725300073623657\n",
      "Epoch 3 Iteration 4 Loss 1.3580129146575928\n",
      "Epoch 3 Iteration 5 Loss 1.3360313177108765\n",
      "Epoch 3 Iteration 6 Loss 1.7022689580917358\n",
      "Epoch 3 Iteration 7 Loss 1.3529175519943237\n",
      "Epoch 3 Iteration 8 Loss 1.1821120977401733\n",
      "Epoch 3 Iteration 9 Loss 1.383780837059021\n",
      "Epoch 3 Iteration 10 Loss 1.4380592107772827\n",
      "Epoch 3 Iteration 11 Loss 1.5291756391525269\n",
      "Epoch 3 Iteration 12 Loss 1.367789387702942\n",
      "Epoch 3 Iteration 13 Loss 1.4156450033187866\n",
      "Epoch 3 Iteration 14 Loss 1.3776425123214722\n",
      "Epoch 3 Iteration 15 Loss 1.2603142261505127\n",
      "Epoch 3 Iteration 16 Loss 1.4559653997421265\n",
      "Epoch 3 Iteration 17 Loss 1.1679058074951172\n",
      "Epoch 3 Iteration 18 Loss 1.2231457233428955\n",
      "Epoch 3 Iteration 19 Loss 1.2504668235778809\n",
      "Epoch 3 Iteration 20 Loss 1.2463936805725098\n",
      "Epoch 3 Iteration 21 Loss 1.3502246141433716\n",
      "Epoch 3 Iteration 22 Loss 1.3948222398757935\n",
      "Epoch 3 Iteration 23 Loss 1.4043129682540894\n",
      "Epoch 3 Iteration 24 Loss 1.3726282119750977\n",
      "Epoch 3 Iteration 25 Loss 1.2801228761672974\n",
      "Epoch 3 Iteration 26 Loss 1.2593127489089966\n",
      "Epoch 3 Iteration 27 Loss 1.2489510774612427\n",
      "Epoch 3 Iteration 28 Loss 1.2435331344604492\n",
      "Epoch 3 Iteration 29 Loss 1.4056764841079712\n",
      "Epoch 3 Iteration 30 Loss 1.2247792482376099\n",
      "Epoch 3 Iteration 31 Loss 1.2404625415802002\n",
      "Epoch 3 Iteration 32 Loss 1.1279451847076416\n",
      "Epoch 3 Iteration 33 Loss 1.1733360290527344\n",
      "Epoch 3 Iteration 34 Loss 1.226499319076538\n",
      "Epoch 3 Iteration 35 Loss 1.038873553276062\n",
      "Epoch 3 Iteration 36 Loss 1.1692211627960205\n",
      "Epoch 3 Iteration 37 Loss 1.1388001441955566\n",
      "Epoch 3 Iteration 38 Loss 1.0194828510284424\n",
      "Epoch 3 Iteration 39 Loss 1.024542212486267\n",
      "Epoch 3 Iteration 40 Loss 1.0626869201660156\n",
      "Epoch 3 Iteration 41 Loss 1.176563024520874\n",
      "Epoch 3 Iteration 42 Loss 1.120697259902954\n",
      "Epoch 3 Iteration 43 Loss 1.16571044921875\n",
      "Epoch 3 Iteration 44 Loss 1.1818381547927856\n",
      "Epoch 3 Iteration 45 Loss 1.1413908004760742\n",
      "Epoch 3 Iteration 46 Loss 0.9770324230194092\n",
      "Epoch 3 Iteration 47 Loss 1.1473997831344604\n",
      "Epoch 3 Iteration 48 Loss 1.2433637380599976\n",
      "Epoch 3 Iteration 49 Loss 1.0773320198059082\n",
      "Epoch 4 Iteration 0 Loss 1.0276284217834473\n",
      "Epoch 4 Iteration 1 Loss 1.0501567125320435\n",
      "Epoch 4 Iteration 2 Loss 1.203827977180481\n",
      "Epoch 4 Iteration 3 Loss 1.1722323894500732\n",
      "Epoch 4 Iteration 4 Loss 1.2214882373809814\n",
      "Epoch 4 Iteration 5 Loss 1.0591846704483032\n",
      "Epoch 4 Iteration 6 Loss 1.1081571578979492\n",
      "Epoch 4 Iteration 7 Loss 1.0792244672775269\n",
      "Epoch 4 Iteration 8 Loss 1.0977272987365723\n",
      "Epoch 4 Iteration 9 Loss 1.0437572002410889\n",
      "Epoch 4 Iteration 10 Loss 0.9625255465507507\n",
      "Epoch 4 Iteration 11 Loss 1.0409808158874512\n",
      "Epoch 4 Iteration 12 Loss 0.9548012614250183\n",
      "Epoch 4 Iteration 13 Loss 0.9719690084457397\n",
      "Epoch 4 Iteration 14 Loss 1.0261577367782593\n",
      "Epoch 4 Iteration 15 Loss 1.1324117183685303\n",
      "Epoch 4 Iteration 16 Loss 1.014685034751892\n",
      "Epoch 4 Iteration 17 Loss 1.0172364711761475\n",
      "Epoch 4 Iteration 18 Loss 1.1830856800079346\n",
      "Epoch 4 Iteration 19 Loss 1.0520633459091187\n",
      "Epoch 4 Iteration 20 Loss 1.0112626552581787\n",
      "Epoch 4 Iteration 21 Loss 0.986179769039154\n",
      "Epoch 4 Iteration 22 Loss 0.9343934059143066\n",
      "Epoch 4 Iteration 23 Loss 1.0126559734344482\n",
      "Epoch 4 Iteration 24 Loss 1.009384274482727\n",
      "Epoch 4 Iteration 25 Loss 0.8683367967605591\n",
      "Epoch 4 Iteration 26 Loss 0.6490482687950134\n",
      "Epoch 4 Iteration 27 Loss 1.0209826231002808\n",
      "Epoch 4 Iteration 28 Loss 0.9831709265708923\n",
      "Epoch 4 Iteration 29 Loss 0.9017253518104553\n",
      "Epoch 4 Iteration 30 Loss 1.0909425020217896\n",
      "Epoch 4 Iteration 31 Loss 1.1598924398422241\n",
      "Epoch 4 Iteration 32 Loss 1.0682910680770874\n",
      "Epoch 4 Iteration 33 Loss 0.8445412516593933\n",
      "Epoch 4 Iteration 34 Loss 1.0193018913269043\n",
      "Epoch 4 Iteration 35 Loss 0.7978839874267578\n",
      "Epoch 4 Iteration 36 Loss 0.9730280637741089\n",
      "Epoch 4 Iteration 37 Loss 0.905861496925354\n",
      "Epoch 4 Iteration 38 Loss 0.9912591576576233\n",
      "Epoch 4 Iteration 39 Loss 1.0852406024932861\n",
      "Epoch 4 Iteration 40 Loss 0.8016020655632019\n",
      "Epoch 4 Iteration 41 Loss 1.0263288021087646\n",
      "Epoch 4 Iteration 42 Loss 0.866599440574646\n",
      "Epoch 4 Iteration 43 Loss 0.9459879994392395\n",
      "Epoch 4 Iteration 44 Loss 0.9117632508277893\n",
      "Epoch 4 Iteration 45 Loss 0.9171954393386841\n",
      "Epoch 4 Iteration 46 Loss 1.070532202720642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Iteration 47 Loss 1.0068241357803345\n",
      "Epoch 4 Iteration 48 Loss 0.7762796878814697\n",
      "Epoch 4 Iteration 49 Loss 0.8388192057609558\n",
      "Epoch 5 Iteration 0 Loss 0.8751064538955688\n",
      "Epoch 5 Iteration 1 Loss 0.8132912516593933\n",
      "Epoch 5 Iteration 2 Loss 0.8409005403518677\n",
      "Epoch 5 Iteration 3 Loss 1.0143119096755981\n",
      "Epoch 5 Iteration 4 Loss 0.8430842161178589\n",
      "Epoch 5 Iteration 5 Loss 0.9215313792228699\n",
      "Epoch 5 Iteration 6 Loss 0.6538724303245544\n",
      "Epoch 5 Iteration 7 Loss 1.0033366680145264\n",
      "Epoch 5 Iteration 8 Loss 0.8117235898971558\n",
      "Epoch 5 Iteration 9 Loss 0.9651161432266235\n",
      "Epoch 5 Iteration 10 Loss 1.0185624361038208\n",
      "Epoch 5 Iteration 11 Loss 0.8018267750740051\n",
      "Epoch 5 Iteration 12 Loss 0.8676580190658569\n",
      "Epoch 5 Iteration 13 Loss 0.8939915299415588\n",
      "Epoch 5 Iteration 14 Loss 0.8649663925170898\n",
      "Epoch 5 Iteration 15 Loss 0.7371720671653748\n",
      "Epoch 5 Iteration 16 Loss 0.7453422546386719\n",
      "Epoch 5 Iteration 17 Loss 0.9951702356338501\n",
      "Epoch 5 Iteration 18 Loss 0.7936350107192993\n",
      "Epoch 5 Iteration 19 Loss 0.7610501646995544\n",
      "Epoch 5 Iteration 20 Loss 0.6961184740066528\n",
      "Epoch 5 Iteration 21 Loss 0.6919148564338684\n",
      "Epoch 5 Iteration 22 Loss 0.8185811042785645\n",
      "Epoch 5 Iteration 23 Loss 0.8067592978477478\n",
      "Epoch 5 Iteration 24 Loss 0.7928766012191772\n",
      "Epoch 5 Iteration 25 Loss 0.8242278695106506\n",
      "Epoch 5 Iteration 26 Loss 0.7924085259437561\n",
      "Epoch 5 Iteration 27 Loss 0.8044406175613403\n",
      "Epoch 5 Iteration 28 Loss 0.9464982748031616\n",
      "Epoch 5 Iteration 29 Loss 0.7807610034942627\n",
      "Epoch 5 Iteration 30 Loss 0.8112133741378784\n",
      "Epoch 5 Iteration 31 Loss 0.6585628390312195\n",
      "Epoch 5 Iteration 32 Loss 0.8438937664031982\n",
      "Epoch 5 Iteration 33 Loss 0.5561160445213318\n",
      "Epoch 5 Iteration 34 Loss 0.8207749724388123\n",
      "Epoch 5 Iteration 35 Loss 0.7781844735145569\n",
      "Epoch 5 Iteration 36 Loss 0.8517505526542664\n",
      "Epoch 5 Iteration 37 Loss 0.7490682005882263\n",
      "Epoch 5 Iteration 38 Loss 0.6637084484100342\n",
      "Epoch 5 Iteration 39 Loss 0.7587246894836426\n",
      "Epoch 5 Iteration 40 Loss 0.8875266909599304\n",
      "Epoch 5 Iteration 41 Loss 0.8199255466461182\n",
      "Epoch 5 Iteration 42 Loss 0.805269181728363\n",
      "Epoch 5 Iteration 43 Loss 0.7477614879608154\n",
      "Epoch 5 Iteration 44 Loss 0.8870400190353394\n",
      "Epoch 5 Iteration 45 Loss 0.7964544892311096\n",
      "Epoch 5 Iteration 46 Loss 0.8966041803359985\n",
      "Epoch 5 Iteration 47 Loss 0.7424634695053101\n",
      "Epoch 5 Iteration 48 Loss 0.662449300289154\n",
      "Epoch 5 Iteration 49 Loss 0.9096724987030029\n",
      "Epoch 6 Iteration 0 Loss 0.7239113450050354\n",
      "Epoch 6 Iteration 1 Loss 0.7971566915512085\n",
      "Epoch 6 Iteration 2 Loss 0.7786869406700134\n",
      "Epoch 6 Iteration 3 Loss 0.6933904886245728\n",
      "Epoch 6 Iteration 4 Loss 0.7303826808929443\n",
      "Epoch 6 Iteration 5 Loss 0.6338272094726562\n",
      "Epoch 6 Iteration 6 Loss 0.7448145151138306\n",
      "Epoch 6 Iteration 7 Loss 0.7641292810440063\n",
      "Epoch 6 Iteration 8 Loss 0.7446818947792053\n",
      "Epoch 6 Iteration 9 Loss 0.6336186528205872\n",
      "Epoch 6 Iteration 10 Loss 0.6906761527061462\n",
      "Epoch 6 Iteration 11 Loss 0.9394902586936951\n",
      "Epoch 6 Iteration 12 Loss 0.64417564868927\n",
      "Epoch 6 Iteration 13 Loss 0.5788456797599792\n",
      "Epoch 6 Iteration 14 Loss 0.6767220497131348\n",
      "Epoch 6 Iteration 15 Loss 0.7352544069290161\n",
      "Epoch 6 Iteration 16 Loss 0.5287868976593018\n",
      "Epoch 6 Iteration 17 Loss 0.7016925811767578\n",
      "Epoch 6 Iteration 18 Loss 0.7488532662391663\n",
      "Epoch 6 Iteration 19 Loss 0.5611935257911682\n",
      "Epoch 6 Iteration 20 Loss 0.5468469858169556\n",
      "Epoch 6 Iteration 21 Loss 0.48996487259864807\n",
      "Epoch 6 Iteration 22 Loss 0.694837749004364\n",
      "Epoch 6 Iteration 23 Loss 0.7421088218688965\n",
      "Epoch 6 Iteration 24 Loss 0.73333740234375\n",
      "Epoch 6 Iteration 25 Loss 0.7083763480186462\n",
      "Epoch 6 Iteration 26 Loss 0.4790203869342804\n",
      "Epoch 6 Iteration 27 Loss 0.6879271864891052\n",
      "Epoch 6 Iteration 28 Loss 0.675383985042572\n",
      "Epoch 6 Iteration 29 Loss 0.7385711073875427\n",
      "Epoch 6 Iteration 30 Loss 0.6596711277961731\n",
      "Epoch 6 Iteration 31 Loss 0.5377504229545593\n",
      "Epoch 6 Iteration 32 Loss 0.795598030090332\n",
      "Epoch 6 Iteration 33 Loss 0.7227849960327148\n",
      "Epoch 6 Iteration 34 Loss 0.7785837650299072\n",
      "Epoch 6 Iteration 35 Loss 0.8899402022361755\n",
      "Epoch 6 Iteration 36 Loss 0.6625990271568298\n",
      "Epoch 6 Iteration 37 Loss 0.8376820683479309\n",
      "Epoch 6 Iteration 38 Loss 0.7688413858413696\n",
      "Epoch 6 Iteration 39 Loss 0.5989018678665161\n",
      "Epoch 6 Iteration 40 Loss 0.8614458441734314\n",
      "Epoch 6 Iteration 41 Loss 0.563072144985199\n",
      "Epoch 6 Iteration 42 Loss 0.7732121348381042\n",
      "Epoch 6 Iteration 43 Loss 0.5275968313217163\n",
      "Epoch 6 Iteration 44 Loss 0.6456159353256226\n",
      "Epoch 6 Iteration 45 Loss 0.7200404405593872\n",
      "Epoch 6 Iteration 46 Loss 0.5992394685745239\n",
      "Epoch 6 Iteration 47 Loss 0.6532554626464844\n",
      "Epoch 6 Iteration 48 Loss 0.6163122057914734\n",
      "Epoch 6 Iteration 49 Loss 0.7208805680274963\n",
      "Epoch 7 Iteration 0 Loss 0.550785481929779\n",
      "Epoch 7 Iteration 1 Loss 0.633693277835846\n",
      "Epoch 7 Iteration 2 Loss 0.7424216270446777\n",
      "Epoch 7 Iteration 3 Loss 0.5114068388938904\n",
      "Epoch 7 Iteration 4 Loss 0.6798980236053467\n",
      "Epoch 7 Iteration 5 Loss 0.5788866877555847\n",
      "Epoch 7 Iteration 6 Loss 0.6268940567970276\n",
      "Epoch 7 Iteration 7 Loss 0.7121841907501221\n",
      "Epoch 7 Iteration 8 Loss 0.6621094942092896\n",
      "Epoch 7 Iteration 9 Loss 0.7010027170181274\n",
      "Epoch 7 Iteration 10 Loss 0.6581329107284546\n",
      "Epoch 7 Iteration 11 Loss 0.7420394420623779\n",
      "Epoch 7 Iteration 12 Loss 0.5761731266975403\n",
      "Epoch 7 Iteration 13 Loss 0.5995696187019348\n",
      "Epoch 7 Iteration 14 Loss 0.774728536605835\n",
      "Epoch 7 Iteration 15 Loss 0.6455554962158203\n",
      "Epoch 7 Iteration 16 Loss 0.48397281765937805\n",
      "Epoch 7 Iteration 17 Loss 0.6092687845230103\n",
      "Epoch 7 Iteration 18 Loss 0.665212094783783\n",
      "Epoch 7 Iteration 19 Loss 0.6729264259338379\n",
      "Epoch 7 Iteration 20 Loss 0.6038210988044739\n",
      "Epoch 7 Iteration 21 Loss 0.6404536366462708\n",
      "Epoch 7 Iteration 22 Loss 0.6497095227241516\n",
      "Epoch 7 Iteration 23 Loss 0.6458780765533447\n",
      "Epoch 7 Iteration 24 Loss 0.5511229038238525\n",
      "Epoch 7 Iteration 25 Loss 0.6812865138053894\n",
      "Epoch 7 Iteration 26 Loss 0.4060411751270294\n",
      "Epoch 7 Iteration 27 Loss 0.4938913881778717\n",
      "Epoch 7 Iteration 28 Loss 0.6113331317901611\n",
      "Epoch 7 Iteration 29 Loss 0.7135795950889587\n",
      "Epoch 7 Iteration 30 Loss 0.5966230630874634\n",
      "Epoch 7 Iteration 31 Loss 0.6506190299987793\n",
      "Epoch 7 Iteration 32 Loss 0.5956440567970276\n",
      "Epoch 7 Iteration 33 Loss 0.5685132741928101\n",
      "Epoch 7 Iteration 34 Loss 0.5305996537208557\n",
      "Epoch 7 Iteration 35 Loss 0.7615513801574707\n",
      "Epoch 7 Iteration 36 Loss 0.4977171719074249\n",
      "Epoch 7 Iteration 37 Loss 0.5370750427246094\n",
      "Epoch 7 Iteration 38 Loss 0.6283290386199951\n",
      "Epoch 7 Iteration 39 Loss 0.3668801486492157\n",
      "Epoch 7 Iteration 40 Loss 0.5091885328292847\n",
      "Epoch 7 Iteration 41 Loss 0.5459992289543152\n",
      "Epoch 7 Iteration 42 Loss 0.44697654247283936\n",
      "Epoch 7 Iteration 43 Loss 0.5832650661468506\n",
      "Epoch 7 Iteration 44 Loss 0.5454087853431702\n",
      "Epoch 7 Iteration 45 Loss 0.577772855758667\n",
      "Epoch 7 Iteration 46 Loss 0.5808281302452087\n",
      "Epoch 7 Iteration 47 Loss 0.5142443180084229\n",
      "Epoch 7 Iteration 48 Loss 0.48328056931495667\n",
      "Epoch 7 Iteration 49 Loss 0.5509210228919983\n",
      "Epoch 8 Iteration 0 Loss 0.40926501154899597\n",
      "Epoch 8 Iteration 1 Loss 0.6591477394104004\n",
      "Epoch 8 Iteration 2 Loss 0.5150196552276611\n",
      "Epoch 8 Iteration 3 Loss 0.5069463849067688\n",
      "Epoch 8 Iteration 4 Loss 0.5365406274795532\n",
      "Epoch 8 Iteration 5 Loss 0.4992961883544922\n",
      "Epoch 8 Iteration 6 Loss 0.5080636739730835\n",
      "Epoch 8 Iteration 7 Loss 0.556254506111145\n",
      "Epoch 8 Iteration 8 Loss 0.5154669880867004\n",
      "Epoch 8 Iteration 9 Loss 0.34895750880241394\n",
      "Epoch 8 Iteration 10 Loss 0.439569354057312\n",
      "Epoch 8 Iteration 11 Loss 0.5064201951026917\n",
      "Epoch 8 Iteration 12 Loss 0.42351454496383667\n",
      "Epoch 8 Iteration 13 Loss 0.5048981308937073\n",
      "Epoch 8 Iteration 14 Loss 0.5147895216941833\n",
      "Epoch 8 Iteration 15 Loss 0.5238176584243774\n",
      "Epoch 8 Iteration 16 Loss 0.757166862487793\n",
      "Epoch 8 Iteration 17 Loss 0.5545802712440491\n",
      "Epoch 8 Iteration 18 Loss 0.6135796308517456\n",
      "Epoch 8 Iteration 19 Loss 0.501671314239502\n",
      "Epoch 8 Iteration 20 Loss 0.37277117371559143\n",
      "Epoch 8 Iteration 21 Loss 0.6021869778633118\n",
      "Epoch 8 Iteration 22 Loss 0.38575300574302673\n",
      "Epoch 8 Iteration 23 Loss 0.7053932547569275\n",
      "Epoch 8 Iteration 24 Loss 0.605466902256012\n",
      "Epoch 8 Iteration 25 Loss 0.5267904996871948\n",
      "Epoch 8 Iteration 26 Loss 0.6446033716201782\n",
      "Epoch 8 Iteration 27 Loss 0.42749735713005066\n",
      "Epoch 8 Iteration 28 Loss 0.5721061825752258\n",
      "Epoch 8 Iteration 29 Loss 0.5136409401893616\n",
      "Epoch 8 Iteration 30 Loss 0.5596328377723694\n",
      "Epoch 8 Iteration 31 Loss 0.5891510844230652\n",
      "Epoch 8 Iteration 32 Loss 0.44774696230888367\n",
      "Epoch 8 Iteration 33 Loss 0.5102157592773438\n",
      "Epoch 8 Iteration 34 Loss 0.4019777774810791\n",
      "Epoch 8 Iteration 35 Loss 0.6384164094924927\n",
      "Epoch 8 Iteration 36 Loss 0.6647400259971619\n",
      "Epoch 8 Iteration 37 Loss 0.46478071808815\n",
      "Epoch 8 Iteration 38 Loss 0.4684959352016449\n",
      "Epoch 8 Iteration 39 Loss 0.7863231301307678\n",
      "Epoch 8 Iteration 40 Loss 0.47511258721351624\n",
      "Epoch 8 Iteration 41 Loss 0.5917186141014099\n",
      "Epoch 8 Iteration 42 Loss 0.572297990322113\n",
      "Epoch 8 Iteration 43 Loss 0.49287378787994385\n",
      "Epoch 8 Iteration 44 Loss 0.5257536172866821\n",
      "Epoch 8 Iteration 45 Loss 0.47949400544166565\n",
      "Epoch 8 Iteration 46 Loss 0.44996508955955505\n",
      "Epoch 8 Iteration 47 Loss 0.5062925815582275\n",
      "Epoch 8 Iteration 48 Loss 0.6469414234161377\n",
      "Epoch 8 Iteration 49 Loss 0.4298718571662903\n",
      "Epoch 9 Iteration 0 Loss 0.5763429999351501\n",
      "Epoch 9 Iteration 1 Loss 0.46428510546684265\n",
      "Epoch 9 Iteration 2 Loss 0.5422863364219666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Iteration 3 Loss 0.5907174944877625\n",
      "Epoch 9 Iteration 4 Loss 0.5392916202545166\n",
      "Epoch 9 Iteration 5 Loss 0.5612115859985352\n",
      "Epoch 9 Iteration 6 Loss 0.4423549771308899\n",
      "Epoch 9 Iteration 7 Loss 0.33490878343582153\n",
      "Epoch 9 Iteration 8 Loss 0.34671837091445923\n",
      "Epoch 9 Iteration 9 Loss 0.4592186510562897\n",
      "Epoch 9 Iteration 10 Loss 0.39029204845428467\n",
      "Epoch 9 Iteration 11 Loss 0.5741882920265198\n",
      "Epoch 9 Iteration 12 Loss 0.5588272213935852\n",
      "Epoch 9 Iteration 13 Loss 0.588877260684967\n",
      "Epoch 9 Iteration 14 Loss 0.35372617840766907\n",
      "Epoch 9 Iteration 15 Loss 0.47406038641929626\n",
      "Epoch 9 Iteration 16 Loss 0.41723722219467163\n",
      "Epoch 9 Iteration 17 Loss 0.424917608499527\n",
      "Epoch 9 Iteration 18 Loss 0.47665783762931824\n",
      "Epoch 9 Iteration 19 Loss 0.5742712616920471\n",
      "Epoch 9 Iteration 20 Loss 0.43611952662467957\n",
      "Epoch 9 Iteration 21 Loss 0.536885678768158\n",
      "Epoch 9 Iteration 22 Loss 0.3453541398048401\n",
      "Epoch 9 Iteration 23 Loss 0.5312268137931824\n",
      "Epoch 9 Iteration 24 Loss 0.6141644716262817\n",
      "Epoch 9 Iteration 25 Loss 0.4807317554950714\n",
      "Epoch 9 Iteration 26 Loss 0.5628741383552551\n",
      "Epoch 9 Iteration 27 Loss 0.4181627035140991\n",
      "Epoch 9 Iteration 28 Loss 0.543254554271698\n",
      "Epoch 9 Iteration 29 Loss 0.5046700239181519\n",
      "Epoch 9 Iteration 30 Loss 0.39339572191238403\n",
      "Epoch 9 Iteration 31 Loss 0.6089040637016296\n",
      "Epoch 9 Iteration 32 Loss 0.34251296520233154\n",
      "Epoch 9 Iteration 33 Loss 0.4127548336982727\n",
      "Epoch 9 Iteration 34 Loss 0.42789381742477417\n",
      "Epoch 9 Iteration 35 Loss 0.5261887907981873\n",
      "Epoch 9 Iteration 36 Loss 0.46289336681365967\n",
      "Epoch 9 Iteration 37 Loss 0.45691072940826416\n",
      "Epoch 9 Iteration 38 Loss 0.3782777488231659\n",
      "Epoch 9 Iteration 39 Loss 0.591844379901886\n",
      "Epoch 9 Iteration 40 Loss 0.49662894010543823\n",
      "Epoch 9 Iteration 41 Loss 0.4112994074821472\n",
      "Epoch 9 Iteration 42 Loss 0.5065541863441467\n",
      "Epoch 9 Iteration 43 Loss 0.5021303296089172\n",
      "Epoch 9 Iteration 44 Loss 0.36214393377304077\n",
      "Epoch 9 Iteration 45 Loss 0.3916657269001007\n",
      "Epoch 9 Iteration 46 Loss 0.5648142695426941\n",
      "Epoch 9 Iteration 47 Loss 0.43886494636535645\n",
      "Epoch 9 Iteration 48 Loss 0.3560958206653595\n",
      "Epoch 9 Iteration 49 Loss 0.4757283329963684\n",
      "Epoch 10 Iteration 0 Loss 0.5346103310585022\n",
      "Epoch 10 Iteration 1 Loss 0.4442269206047058\n",
      "Epoch 10 Iteration 2 Loss 0.48893794417381287\n",
      "Epoch 10 Iteration 3 Loss 0.4249912202358246\n",
      "Epoch 10 Iteration 4 Loss 0.45035994052886963\n",
      "Epoch 10 Iteration 5 Loss 0.4609907269477844\n",
      "Epoch 10 Iteration 6 Loss 0.5173898339271545\n",
      "Epoch 10 Iteration 7 Loss 0.5122828483581543\n",
      "Epoch 10 Iteration 8 Loss 0.5141357779502869\n",
      "Epoch 10 Iteration 9 Loss 0.6745826601982117\n",
      "Epoch 10 Iteration 10 Loss 0.4177294373512268\n",
      "Epoch 10 Iteration 11 Loss 0.38905805349349976\n",
      "Epoch 10 Iteration 12 Loss 0.5636283159255981\n",
      "Epoch 10 Iteration 13 Loss 0.41369640827178955\n",
      "Epoch 10 Iteration 14 Loss 0.4647826552391052\n",
      "Epoch 10 Iteration 15 Loss 0.3707623779773712\n",
      "Epoch 10 Iteration 16 Loss 0.44328373670578003\n",
      "Epoch 10 Iteration 17 Loss 0.31772324442863464\n",
      "Epoch 10 Iteration 18 Loss 0.31060144305229187\n",
      "Epoch 10 Iteration 19 Loss 0.3774569630622864\n",
      "Epoch 10 Iteration 20 Loss 0.3955308794975281\n",
      "Epoch 10 Iteration 21 Loss 0.41313472390174866\n",
      "Epoch 10 Iteration 22 Loss 0.3646208345890045\n",
      "Epoch 10 Iteration 23 Loss 0.3916656970977783\n",
      "Epoch 10 Iteration 24 Loss 0.3283984065055847\n",
      "Epoch 10 Iteration 25 Loss 0.5483455061912537\n",
      "Epoch 10 Iteration 26 Loss 0.3895033001899719\n",
      "Epoch 10 Iteration 27 Loss 0.462889164686203\n",
      "Epoch 10 Iteration 28 Loss 0.5019837617874146\n",
      "Epoch 10 Iteration 29 Loss 0.26310160756111145\n",
      "Epoch 10 Iteration 30 Loss 0.39362964034080505\n",
      "Epoch 10 Iteration 31 Loss 0.4928528666496277\n",
      "Epoch 10 Iteration 32 Loss 0.526467502117157\n",
      "Epoch 10 Iteration 33 Loss 0.4733487069606781\n",
      "Epoch 10 Iteration 34 Loss 0.3267875909805298\n",
      "Epoch 10 Iteration 35 Loss 0.49761515855789185\n",
      "Epoch 10 Iteration 36 Loss 0.3531339168548584\n",
      "Epoch 10 Iteration 37 Loss 0.39333027601242065\n",
      "Epoch 10 Iteration 38 Loss 0.28215205669403076\n",
      "Epoch 10 Iteration 39 Loss 0.36740976572036743\n",
      "Epoch 10 Iteration 40 Loss 0.40977030992507935\n",
      "Epoch 10 Iteration 41 Loss 0.5094279646873474\n",
      "Epoch 10 Iteration 42 Loss 0.43312957882881165\n",
      "Epoch 10 Iteration 43 Loss 0.43890655040740967\n",
      "Epoch 10 Iteration 44 Loss 0.40716683864593506\n",
      "Epoch 10 Iteration 45 Loss 0.38991498947143555\n",
      "Epoch 10 Iteration 46 Loss 0.4013032019138336\n",
      "Epoch 10 Iteration 47 Loss 0.5555030703544617\n",
      "Epoch 10 Iteration 48 Loss 0.47523874044418335\n",
      "Epoch 10 Iteration 49 Loss 0.4851989150047302\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "for e in range(10):\n",
    "    it_ = iter(data_loader)\n",
    "    for i in range(50) :\n",
    "        x, y = next(it_)\n",
    "        \n",
    "        x = x.float().reshape(-1, inp*inp).requires_grad_()\n",
    "        y = torch.argmax(y, dim=1)\n",
    "        \n",
    "        out = net(x)\n",
    "        \n",
    "        l = loss(out, y)\n",
    "\n",
    "        print(f\"Epoch {e+1} Iteration {i} Loss {l}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 85.45454545454545 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, inp*inp).float()\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        outputs = net(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
