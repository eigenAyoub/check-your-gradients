{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0 Loss 3.915478229522705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben-ks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "\n",
    "from MNISTDataset import MNISTDataset\n",
    "from sklearn import datasets\n",
    "\n",
    "torch.manual_seed(17)\n",
    "np.random.seed(17)\n",
    "\n",
    "N = 1600\n",
    "batch = 32\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "g_train = MNISTDataset(digits.data[:1600], digits.target[:1600], N)\n",
    "data_loader = DataLoader(g_train, batch_size =  32, shuffle=True)\n",
    "\n",
    "g_test = MNISTDataset(digits.data[1600:], digits.target[1600:], 1765-N)\n",
    "test_loader = DataLoader(g_test, batch_size =  32, shuffle=True)\n",
    "\n",
    "# simple NN:\n",
    "class NN(nn.Module):   \n",
    "    def __init__(self, n1, n2, n3):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(n1, n2)\n",
    "        self.act = nn.ReLU()        \n",
    "        self.lin2 = nn.Linear(n2, n3)\n",
    "        self.soft = nn.Softmax()\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        out = self.lin1(x)\n",
    "        out = self.act(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.soft(out)\n",
    "\n",
    "        return out \n",
    "\n",
    "inp = 8\n",
    "net = NN(inp*inp, 100, 10)\n",
    "\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "for e in range(1):\n",
    "    it_ = iter(data_loader)\n",
    "    for i in range(1) :\n",
    "        x, y = next(it_)\n",
    "        \n",
    "        x = x.float().reshape(-1, inp*inp).requires_grad_()\n",
    "        y = torch.argmax(y, dim=1)\n",
    "        \n",
    "        out = net(x)  \n",
    "        \n",
    "        # logSoftmax:\n",
    "        logout = torch.log(out)\n",
    "        logout.retain_grad()\n",
    "        \n",
    "        # NLLLoss:\n",
    "        l = loss(logout, y)\n",
    "        l.retain_grad()\n",
    "        \n",
    "        # up to here it is working so fucking fine.\n",
    "        # now debug the shit out of your backprop dude!\n",
    "        \n",
    "        print(f\"Epoch {e+1} Iteration {i} Loss {l}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = net.lin1.weight\n",
    "W2 = net.lin2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0290,  ...,  0.1403,  0.0747,  0.0018],\n",
       "        [ 0.0000,  0.0000, -0.0044,  ..., -0.0206,  0.0176,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0039,  ...,  0.0257,  0.0090,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000, -0.0058, -0.0252,  ...,  0.1467,  0.0451,  0.0033],\n",
       "        [ 0.0000,  0.0312,  0.1842,  ...,  0.0575,  0.0076, -0.0032],\n",
       "        [ 0.0000,  0.0000,  0.0043,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.2030, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logout[0][y[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7), tensor(3.9155))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1], l.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 85.45454545454545 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben-ks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, inp*inp).float()\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        outputs = net(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
